# both
initial_model_path: /home/test/testdata/models/Meta-Llama-3-8B-Instruct
initial_dataset_path: ""
dataset_type: cbt
mid_yaml_root_path: ./alignment-handbook/recipes/Llama3-8b/cbt_sft_dpo
check_point_root_path: ./checkpoints/cbt_sft_dpo
iteration_times: 3
port: 8000
devices: 7
tokenizer_first_path: /home/test/testdata/models/Meta-Llama-3-8B-Instruct
tokenizer_second_path: /home/test/testdata/models/Meta-Llama-3-8B-Instruct
explore_count: 10
thread_count: 36
prompt_pool_path: ./utils/prompts_diverse.jsonl
# sft
origin_sft_yaml_path: ./alignment-handbook/recipes/Llama3-8b/cbt_sft_dpo/sft/base.yaml
mid_sft_jsonl_root_path: ./results/cbt_sft_dpo/sft
mid_sft_dataset_root_path: ./my_datasets/cbt_sft_dpo/sft
initial_episilon: 0.5
sample_count: 10000
# dpo
origin_dpo_yaml_path: ./alignment-handbook/recipes/Llama3-8b/cbt_sft_dpo/dpo/base.yaml
mid_dpo_jsonl_root_path: ./results/cbt_sft_dpo/dpo
mid_dpo_dataset_root_path: ./my_datasets/cbt_sft_dpo/dpo
initial_dpo_min_value: 0.2
initial_dpo_episilon: 0.40
monte_sample_count: 12000
cal_ppl: 1
lambda1: -0.6
lambda2: 1
from_initial: False